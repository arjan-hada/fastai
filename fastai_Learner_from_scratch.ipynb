{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_Learner_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3cxDTSIc7nz0e9tz0F31q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjan-hada/fastai/blob/master/fastai_Learner_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of fastai Learner from scratch"
      ],
      "metadata": {
        "id": "PcQBjkh9GYqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will build a fastai Learner from scratch and apply it for classification of letters 3 and 7 from a sample of MNIST dataset."
      ],
      "metadata": {
        "id": "I3eTI16EGc3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Packages\n",
        "\n",
        "Let's first import all the packages we will need for this assignment."
      ],
      "metadata": {
        "id": "9gk8gtpEGwtu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Go5HnT_YZqki"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "metadata": {
        "id": "yNHP4SiQZuzT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Preparing the dataset"
      ],
      "metadata": {
        "id": "991g2Ai6pB4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the dataset\n",
        "\n",
        "Download a sample of MNIST dataset that contain images of 3s and 7s."
      ],
      "metadata": {
        "id": "IRpV7-wlpX4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)"
      ],
      "metadata": {
        "id": "p_36NVQBaC45"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peek inside directory using fastai ls() method.\n"
      ],
      "metadata": {
        "id": "ANU9oDmE0U8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path.ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQPZbLmSaLZ2",
        "outputId": "e678f6fc-9673-49c9-83f2-09b5f65b2bf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [Path('/root/.fastai/data/mnist_sample/train'),Path('/root/.fastai/data/mnist_sample/labels.csv'),Path('/root/.fastai/data/mnist_sample/valid')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peek inside the train folder."
      ],
      "metadata": {
        "id": "97pBW-i-0YKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(path/'train').ls()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVRnSo9TcT0_",
        "outputId": "c2d763f9-2891-4178-9638-0311de5d43f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) [Path('/root/.fastai/data/mnist_sample/train/3'),Path('/root/.fastai/data/mnist_sample/train/7')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peek inside the train folder's 3s and 7s."
      ],
      "metadata": {
        "id": "syqXZpaJ0big"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threes = (path/'train'/'3').ls().sorted()\n",
        "sevens = (path/'train'/'7').ls().sorted()"
      ],
      "metadata": {
        "id": "moUbi4jyaNLu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image to tensors\n",
        "\n",
        "Open the images using Image class is from Python Imaging Library (PIL). Create a tensor containing all the images in a directory."
      ],
      "metadata": {
        "id": "q0hct4QDpb_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
        "\n",
        "len(three_tensors), len(seven_tensors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VofG2AWzaoBr",
        "outputId": "280f3e9a-ad82-42fb-bfbf-333629efd18c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6131, 6265)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check one of the image. Use fastai's show_image function to display tensor as image. Each element of the lists - three_tensors or seven_tensors is 28x28."
      ],
      "metadata": {
        "id": "LTdZ0rdC0wpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(three_tensors[0]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "MQP04AJYbZ4G",
        "outputId": "0e9db64c-8327-450a-b015-5810a5959ce6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine all the images in the list into a single rank-3 tensor. Normalize the pixel values to be between 0 and 1."
      ],
      "metadata": {
        "id": "aw8GePRc07t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_threes.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeLnkoUFbqpy",
        "outputId": "3e97c174-d50e-493f-d034-60e682457b64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6131, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and Validation Dataset\n",
        "\n",
        "Concatenate all the independent variable the images themselves into a single tensor. Technically speaking, change from a list of matrices to a list of vectors or change from a rank-3 tensor to a rank-2 tensor.\n"
      ],
      "metadata": {
        "id": "CAygYhZepkUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
      ],
      "metadata": {
        "id": "Ho3FIJXtgmhZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code dependent variable for each image - 1 for 3s and 0 for 7s."
      ],
      "metadata": {
        "id": "ABgqNOP81WcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
        "train_x.shape, train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6JoxbiekA-r",
        "outputId": "62f1bf00-efb7-4d3d-b10c-ef101f632a4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dataset in Pytorch is required to return a tuple of (x,y) when indexed."
      ],
      "metadata": {
        "id": "VgJZnFAe1dq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dset = list(zip(train_x, train_y))\n",
        "x, y = dset[0]\n",
        "x.shape, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgG-1PF5lLbS",
        "outputId": "440927d8-5c09-4d02-d3f0-bc4058868153"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), tensor([1]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same for validation dataset."
      ],
      "metadata": {
        "id": "8ajYMq4-1mEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor containing all the images in validation folder\n",
        "# Combine all the images in the list into a single rank-3 tensor\n",
        "# Normalize the pixel values between 0 and 1\n",
        "valid_3_tens = torch.stack([tensor(Image.open(o)) \n",
        "  for o in (path/'valid/3').ls()])\n",
        "valid_3_tens = valid_3_tens.float()/255\n",
        "valid_7_tens = torch.stack([tensor(Image.open(o)) \n",
        "  for o in (path/'valid/7').ls()])\n",
        "valid_7_tens = valid_7_tens.float()/255"
      ],
      "metadata": {
        "id": "CDl1my2dl-RV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a validation dataset\n",
        "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
        "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
        "\n",
        "# A dataset in Pytorch is required to create a tuple of (x,y) when indexed\n",
        "valid_dset = list(zip(valid_x, valid_y)) "
      ],
      "metadata": {
        "id": "c3v8BrocIADu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - Creating the DataLoader object\n",
        "\n",
        "Create a DataLoader object for train set. A DataLoader can take any Python collection and turn it into an iterator many batches. A pytorch neural network expects the data to come in the form of minibatches of tensors.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gfn2VM3ppqkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(dset, batch_size=256)\n",
        "xb,yb = first(dl)\n",
        "xb.shape,yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVD9x2TxK7If",
        "outputId": "c3efca69-142d-4d80-b17e-a5c4968a1a94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 784]), torch.Size([256, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataLoader object for validation set."
      ],
      "metadata": {
        "id": "LW4N3xkE2BQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dl = DataLoader(valid_dset, batch_size=256)"
      ],
      "metadata": {
        "id": "Xowwp8iYPDwP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a DataLoaders, by passing our training and validation DataLoaders."
      ],
      "metadata": {
        "id": "HQ9P_vFU2FvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders(dl, valid_dl)"
      ],
      "metadata": {
        "id": "DRypn7WxWDPA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - End-to-end Stochastic Gradient Descent\n",
        "\n",
        "Implementation of Learner from scratch."
      ],
      "metadata": {
        "id": "NcxAcVUmpwS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_params(size, std=1.0):\n",
        "  return (torch.randn(size)*std).requires_grad_()\n",
        "\n",
        "def linear1(xb): return xb@weights + bias\n",
        "\n",
        "def mnist_loss(predictions, targets):\n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "def batch_accuracy(xb, yb):\n",
        "  preds = xb.sigmoid()\n",
        "  correct = (preds>0.5) == yb\n",
        "  return correct.float().mean()\n",
        "\n",
        "class BasicOptim:\n",
        "  def __init__(self, params, lr): self.params, self.lr = list(params), lr\n",
        "\n",
        "  def step(self, *args, **kwargs):\n",
        "    for p in self.params:\n",
        "      p.data -= p.grad.data*self.lr\n",
        "  \n",
        "  def zero_grad(self, *args, **kwargs):\n",
        "    for p in self.params: p.grad = None\n",
        "\n",
        "def train_model(model, epochs):\n",
        "  results = defaultdict(list)\n",
        "  for i in range(epochs):\n",
        "\n",
        "    train_epoch_loss = []\n",
        "    # Training epoch\n",
        "    for xb,yb in dl: # Forward propagation\n",
        "      preds = model(xb)\n",
        "      loss = mnist_loss(preds, yb)\n",
        "      train_epoch_loss.append(loss)\n",
        "      loss.backward() # Backward propagation or Calculate gradient of the loss function\n",
        "      opt.step() # Update parameters\n",
        "      opt.zero_grad()\n",
        "\n",
        "    accs = []\n",
        "    valid_epoch_loss = []\n",
        "    # Validation epoch\n",
        "    for xb, yb in valid_dl:\n",
        "      preds = model(xb)\n",
        "      loss = mnist_loss(preds, yb)\n",
        "      valid_epoch_loss.append(loss)\n",
        "      accs.append(batch_accuracy(preds, yb))\n",
        "      \n",
        "\n",
        "    results['epoch'].append(i)\n",
        "    results['train_loss'].append(\n",
        "        round(torch.stack(train_epoch_loss).mean().item(), 4))\n",
        "    results['valid_loss'].append(\n",
        "        round(torch.stack(valid_epoch_loss).mean().item(), 4))\n",
        "    results['batch_accuracy'].append(round(torch.stack(accs).mean().item(), 4))\n",
        "  return pd.DataFrame.from_dict(results)"
      ],
      "metadata": {
        "id": "OiIec-8f3fKE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the parameters and train\n",
        "weights = init_params((28*28, 1))\n",
        "bias = init_params(1)\n",
        "params = weights, bias\n",
        "lr = 1\n",
        "\n",
        "linear_model = linear1\n",
        "opt = BasicOptim(params, lr)\n",
        "train_model(linear_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_GvQ2LuJ31Z-",
        "outputId": "eafc1c61-a556-4d6d-8cfa-09351b8abeda"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   epoch  train_loss  valid_loss  batch_accuracy\n",
              "0      0      0.1791      0.3488          0.6468\n",
              "1      1      0.1094      0.1773          0.8270\n",
              "2      2      0.0743      0.1059          0.8997\n",
              "3      3      0.0605      0.0788          0.9227\n",
              "4      4      0.0523      0.0634          0.9403\n",
              "5      5      0.0473      0.0541          0.9501\n",
              "6      6      0.0433      0.0483          0.9540\n",
              "7      7      0.0400      0.0443          0.9569\n",
              "8      8      0.0371      0.0413          0.9579\n",
              "9      9      0.0349      0.0388          0.9623"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf01b4f7-86a8-4ff3-b3b5-9dd31ae0606d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.3488</td>\n",
              "      <td>0.6468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.1094</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.8270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0743</td>\n",
              "      <td>0.1059</td>\n",
              "      <td>0.8997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0605</td>\n",
              "      <td>0.0788</td>\n",
              "      <td>0.9227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0634</td>\n",
              "      <td>0.9403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0473</td>\n",
              "      <td>0.0541</td>\n",
              "      <td>0.9501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0433</td>\n",
              "      <td>0.0483</td>\n",
              "      <td>0.9540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0400</td>\n",
              "      <td>0.0443</td>\n",
              "      <td>0.9569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0413</td>\n",
              "      <td>0.9579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0349</td>\n",
              "      <td>0.0388</td>\n",
              "      <td>0.9623</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf01b4f7-86a8-4ff3-b3b5-9dd31ae0606d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf01b4f7-86a8-4ff3-b3b5-9dd31ae0606d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf01b4f7-86a8-4ff3-b3b5-9dd31ae0606d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the result of our implementation from fastai's Learner object"
      ],
      "metadata": {
        "id": "sl8i41NFzCZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD, \n",
        "                loss_func=mnist_loss, metrics=batch_accuracy)\n",
        "learn.fit(10, 1)"
      ],
      "metadata": {
        "id": "tTLpnR2S9XRq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "920436b4-be20-468f-c73b-83f038c0ea6a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>batch_accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.637359</td>\n",
              "      <td>0.503291</td>\n",
              "      <td>0.495584</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.465036</td>\n",
              "      <td>0.246566</td>\n",
              "      <td>0.779686</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.173200</td>\n",
              "      <td>0.160938</td>\n",
              "      <td>0.854760</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.076995</td>\n",
              "      <td>0.100013</td>\n",
              "      <td>0.915604</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.041545</td>\n",
              "      <td>0.074687</td>\n",
              "      <td>0.934740</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.027667</td>\n",
              "      <td>0.060542</td>\n",
              "      <td>0.948970</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.021943</td>\n",
              "      <td>0.051562</td>\n",
              "      <td>0.956820</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.019379</td>\n",
              "      <td>0.045523</td>\n",
              "      <td>0.963199</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018064</td>\n",
              "      <td>0.041255</td>\n",
              "      <td>0.965653</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.017261</td>\n",
              "      <td>0.038099</td>\n",
              "      <td>0.966634</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}